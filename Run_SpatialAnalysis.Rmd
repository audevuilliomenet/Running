---
title: "Run_SpatialAnalysis"
author: "Aude Vuilliomenet"
date: "12/26/2018"
output: html_document
runtime: shiny
---
```{r}
library(sp)
library(sf)
library(dplyr)
library(tmap)
```
Introduction:
This project tries to understand where the people in London run. To answer this question, a sample of recorded runs from the application Mapmyrun was downloaded. In this project, the analysis of 381 running route is made. The routes correspond to the routes uploading by Mapmyrun users between the 21st and 30th of November 2018. 
Goal:
1. Calculate the length of each route and understand the running distance of the MapmyRun runners. 
2. Calculate the coordinate point of the start of each route. Understand where the people start to run. Is there any spatial clustering?
3. Calculate the intersection of the run with the LondonWards. Are there some wards that are more attractive than others? Spatial clustering analysis. 
4. Create a shiny application to visualize running distance histogram, starting location distribution, wards distribution.

The following R markdowm show each steps of the coding for doing the analysis of the Running routes.

First a list with all the uploaded running data is created. As Mapmyrun recorded not only entire route (linestring) but also the coordinate points for each miles of the run, there is the necessity of cleaning a little bit the data. The for loops selects therefore only the 1st row of each run (this row represents the running route (linestring)). Each of the linestrings are then append to a dataframe (dataframe_allrun_november). 

```{r}
setwd("/Users/audevuilliomenet/Documents/MSc. Smart Cities/GI Systems and Science/GIS_Running/Running/Run_November.kml")

run_november <- list.files()

first_running <- data.frame(sf::st_read(run_november[1]))
dataframe_allrun_november <- first_running[1,]

for (index in 2:length(run_november)){
  read_run <- data.frame(sf::st_read(run_november[index]))
  firstrow_run <- read_run[1,]
  dataframe_allrun_november <- rbind(dataframe_allrun_november, firstrow_run) 
  print(dataframe_allrun_november)
} 
```
Mapmyrun records the x,y and z geometry. The z geometry gives information on the height profile. Even if the z geometry would be interesting to analyse, it was chosen to remove it for the further exploration of the data. It is indeed much more convenient to remove the z geometry to handle the data. The next steps change the dataframe to an sf object dataframe An sf dataframe has the advantage of containing spatial information (here geometry lines) and allow to make geographic calculation such as calculate the length of each route. 
```{r}
# Change the dataframe to an sf object
allrun_november_sf <- sf::st_sf(dataframe_allrun_november) 
# Delete the z-coordinate of the run
allrun_november_sf <- st_zm(allrun_november_sf, drop = TRUE, what = "ZM")
# Set the coorindate system of the road to the WGS84. Here WGS84 is choosen rather than British National Grid, as for later use in leaflet, WGS84 is prefered!
WGS84 <- "+init=epsg:4326"
allrun_november_sf  <- st_transform(allrun_november_sf, WGS84)
# Delete a column we don't need it!
allrun_november_sf  <- allrun_november_sf[,-2]
View(allrun_november_sf)
```
Before starting with any analyses, let's have a quick look at the running data.
```{r}
# View the run routes on an interactive map. 
tmap_mode("view")
tm_shape(allrun_november_sf) +
  tm_lines(col = "blue", lwd = 4, alpha = 0.5)
```
Research Question 1 - What are the distance usually run by Mapmyrun users. 

In order to do some descriptive statitics to understand what are the most common distances run, we need to calculate the length of each running route. 
```{r}
run_length_november <- st_length(allrun_november_sf)
# Append the run_length to the dataframe!
allrun_november_sf <- cbind(allrun_november_sf,run_length_november)
View(allrun_november_sf)
```
It might be interesting to categorize the running routes depending on their length. Here three groups are formed. The routes that are up to 5 km are named "short run", the routes that are between 5km and 10km are classified as "intermediate run", the others, with a distance greater than 10km are named "long run".
```{r}
allrun_november_sf$run_length_november <- as.numeric(run_length_november)
# Define the three categories, short run, intermediate run and long run. Add it as a column in the dataframe. 
allrun_november_sf$distance <- ifelse(allrun_november_sf$run_length_november <= 5000, "Short Run",
                             ifelse((allrun_november_sf$run_length_november >= 5000 & allrun_november_sf$run_length_november <= 10000), "Intermediate Run","Long Run"))
```
Now that we have the lenght of all run, we can create an histogram to see the distribution of the run. 
```{r}
# Extract the run length colunm from the allrun_november_sf dataframe!
rln <- allrun_november_sf[,2]
# Drop the geometry
rln <- st_set_geometry(rln, NULL)
# Create the histogram for the distribution with ggplot!
library(ggplot2)
histogram <- ggplot(rln, aes(x=run_length_november)) +
  geom_histogram(aes(y=..density..), colour="white") + 
                   geom_density(color="blue", size=0.5) +
                   geom_vline(aes(xintercept=median(run_length_november), color="red"))+
plot(histogram)

# Create a box plot for running distribution
# dist_run <-  allrun_november_sf[,4]
# Drop the geometry
# dist_run <- st_set_geometry(dist_run, NULL)

# boxplot <- ggplot(dist_run, aes(x=distance))+geom_boxplot()
# plot(boxplot)
```
Research Question 2 - Where do the people start to run? 

The following analysis will be a spatial analysis to see if there are any clustering, spatial aggregation of the starting location of the runs. First, we need to extract the first coordinate point of all the running route. Then, it would be possible to map this geographic points inside the LondonWards. And finally, to do a spatial analysis. 

Let's start by calculating the start location of each run! 
```{r}
# Transfrom the sf object to an sp object! It will be easier to extract the first latitude/longitude for each path. 
run_november_sp <- as(allrun_november_sf, "Spatial")

# create a dataframe for adding the first lng/lat of each running path!
#### Longitude ####
longitude <- data.frame(run_november_sp@lines[[1]]@Lines[[1]]@coords[1,1])
longitude <- longitude[1,]
#### Latitude ####
latitude <- data.frame(run_november_sp@lines[[1]]@Lines[[1]]@coords[1,2])
latitude <- latitude[1,]

# loops through all the file in SpatialLine Dataframe!
# selection only the first longitude value of the running path.
# append the value to the lng dataframe. 
# Do the same for the latitude!
#### Longitude ####
for (i in 2:nrow(run_november_sp)){
  get_lng <-  run_november_sp@lines[[i]]@Lines[[1]]@coords[1,1]
  longitude <- rbind(longitude,get_lng)
}
#### Latitude ####
for (i in 2:nrow(run_november_sp)){
  get_lat <-  run_november_sp@lines[[i]]@Lines[[1]]@coords[1,2]
  latitude <- rbind(latitude,get_lat)
}
# Append both lng/lat to the data of run_dataframe_sp!
run_november_sp@data$longitude <- cbind(run_november_sp@data$longitude, longitude) 
run_november_sp@data$latitude <- cbind(run_november_sp@data$latitude, latitude) 

# Transform back to an sf object!
run_november_sf <- st_as_sf(run_november_sp)
# Drop the linestrings geometry! Here we are only interested in the start of the run!
start_point <- st_set_geometry(run_november_sf, NULL)

# Set the geometry from the coordinate of the starting point! 
start_point <-  st_as_sf(start_point,  coords = c("longitude", "latitude"),crs=WGS84)
```

Now we need the LondonWards boundaries. 
```{r}
library(rgdal)
LondonWards <- readOGR("/Users/audevuilliomenet/Documents/MSc. Smart Cities/GI Systems and Science/GIS_Running/Running/LondonWardsBoundaries/LondonWardsNew.shp", layer="LondonWardsNew")

# Transfrom the LondonWards to an sf object and set coordinate system same as the run_dataframe_sf (WGS84). 
LondonWards_sf <- st_as_sf(LondonWards)
LondonWards_sf <- st_transform(LondonWards_sf, WGS84)
# Delete some of the column in Londonwards_sf
LondonWards_sf <- LondonWards_sf[,-5]
```
Let's have a quick view of the distribution of the starting run! 
```{r}
tmap_mode("view")
tm_shape(LondonWards_sf) +
  tm_polygons(col = NA, alpha = 0.2)+
  tm_shape(start_point)+
  tm_dots(col = "blue", size=0.04)
```
To be able to analyse the distribution of the starting run, we need to count how many starting points are in each ward. Here we need to transform both object back to sp object!
The analysis is here in three steps. First, the number of points to be found in each ward is calculated, then the density of points for each ward is calculated and a quick cloropleth map is made. After visualizing the distribution, the spatial analysis is made using a Moran I's, Geary's C and Getis Ord General G test. 
```{r}
## Transform start location and LondonWards Map to sp DataFrame 
start_point_sp <- as(start_point,"Spatial")
LondonWards_sp <- as(LondonWards_sf, "Spatial")
## Counts the number of hunt in each wards. "poly.counts" function!
library(GISTools)
counts_start_point <- poly.counts(start_point_sp, LondonWards_sp)
class(counts_start_point)
View(counts_start_point)
```
```{r}
# Add the count number as a column in the spatialPolygonsDataframe
LondonWards_sp@data$startrun_count <- counts_start_point
# Calculate the density -> Wards are of different size!
LondonWards_sp@data$startrundensity <- LondonWards_sp$startrun_count/poly.areas(LondonWards_sp)
LondonWards_sp@data

# Quick Choropleth map 
tm_shape(LondonWards_sp) +
  tm_polygons("startrundensity",
              style="jenks",
              palette="RdBu",
              midpoint=NA,
              title="Start Run Density")
```
```{r}
# Check with a Moran's I test for clustering!
library(spdep)
# Calculate centroids for all Wards in London
coordsW <- coordinates(LondonWards_sp)
# Generate a spatial weights matrix and create a neighbours list
LWard_nb <- poly2nb(LondonWards_sp, queen=T)
# Create a spatial weights object from these weights
Lward.lw <- nb2listw(LWard_nb, style="C")

# Moran's I test -> cluster value (=1) or dispersed values (=-1)
moranI_start_run <- moran.test(LondonWards_sp@data$startrundensity, Lward.lw)
moranI_start_run
## moranI_hunt = 0.14 -> no autocorrelation (almost perfect randomness!)

# Geary's C test -> similar values or dissimilar values clustering?
gearyC_start_run <- geary.test(LondonWards_sp@data$startrundensity, Lward.lw)
gearyC_start_run
## gearyC_hunt = 0.68 -> no clear spatial autocorrelation, indicate rather a positive one. Similar values tend to cluster! 

# Getis Ord General G -> high or low values are clustering!
globalG_start_run <- globalG.test(LondonWards_sp@data$startrundensity, Lward.lw)
globalG_start_run
## globalGhunt: G statistic = 0.009 > G Expectation = 0.002
## High Values tend to cluster
```
Research Question 3 - What are the wards where the most people run? 

This third question will also be answered through the use of spatial analysis method. Here we need to find in which wards do the running routes passed through. 
First, the intersection of all running routes with the LondonWards is find and the number of running routes passing through a wards is counted. Then, it is possible to use Moran I's, Geary's C and Getis Ord General G test. 
```{r}
# Find the intersection of the running route with the LondonWards. 
wards_run_intersect <- st_intersects(LondonWards_sf, allrun_november_sf)
View(wards_run_intersect)
# For the first ward. Find all the run passing through the first ward. Make a dataframe with the run id and count the number of run in the dataframe. (sum the column!) 
first_ward <- wards_run_intersect[1]
run_i_df <- data.frame(first_run)
count_df <- count(run_i_df)

# For loop to find the total run passing through a ward. 
for (i in 2:nrow(wards_run_intersect)){
  run_i <- wards_run_intersect[i]
  run_i_df <- data.frame(run_i)
  count_run <- count(run_i_df)
  # Save the values in the count_df dataframe!
  count_df <- rbind(count_df, count_run)
}

# Rename the column of count_df
names(count_df)[1] <- "count_run"
# Change the dataframe to vector!
count_run <- data.matrix(count_df)
count_run <- as.numeric(count_run)
class(count_run)
# Append the count_run to the LondonWards sp DataFrame!
LondonWards_sp@data$count_run <- count_run
# Calculate the density for the number of route passing through the LondonWards!
LondonWards_sp@data$count_run_density <- LondonWards_sp$count_run/poly.areas(LondonWards_sp)
```

```{r}
# Quick Choropleth map 
tm_shape(LondonWards_sp) +
  tm_polygons("count_run",
              style="jenks",
              palette="RdBu",
              midpoint=NA,
              title="Number of running route for each London ward")

# Quick Choropleth map for density!
tm_shape(LondonWards_sp) +
  tm_polygons("count_run_density",
              style="jenks",
              palette="RdBu",
              midpoint=NA,
              title="Density of running route for each London ward")
```


```{r}
# Save the values in a dataframe
wards_run_intersect_df <-  data.frame(wards_run_intersect)
# Rename the column of the dataframe to be more coherant!
names(wards_run_intersect_df)[1] <- "WardID"
names(wards_run_intersect_df)[2] <- "RunID"

# Rename the column name for LondonWards_sf to be the same as in wards_run_intersect_df.
names(LondonWards_sf)[1] <- "WardID" 
names(LondonWards_sf)[4] <- "WardName"
names(LondonWards_sf)[2] <- "WardCode"

#### Append the Allrun November and LondonWards dataframes to the wards_run_intersect dataframe
# This allow us to have the run geometry and the LondonWards name for each corresponding run!
# Create a new column for allrun_november_sf dataframe 
RunID <- seq(1,length(run_november))
run_november_sf <- cbind(run_november_sf,RunID)
# Append the Running Coordinate to the run_november_sf dataframe!
run_november_RunID <- merge(wards_run_intersect_df,run_november_sf, by="RunID")
# Append the LondonWards to the run_november dataframe. 
run_november_WardID <- merge(run_november_RunID,LondonWards_sf, by="WardID")
View(run_november_WardID)
# Delete the geometry for the LondonWards
run_november_WardID <-  run_november_WardID[,-c(14)]
# Rename the run_november_WardID geometry!
names(run_november_WardID)[8] <- "geometry"
## Transfrom run_november_WardID back to an sf object!
run_november_sf <- st_as_sf(run_november_WardID)
summary(run_november_sf)

# Transform the coordinate system to WGS84 to be able to plot with leaflet!
WGS84 <- "+init=epsg:4326"
run_november <- st_transform(run_november_sf, WGS84)
# Transform rund_dataframe to an sp object! Use in leaflet!
run_november_sp <- as(run_november, "Spatial")
run_november_sp@data$WardName

## Function to selection the Ward to start from!
RunInWard <- function(run_november_sp){
  vars <- readline("Please enter the Ward you would like to start your run")
 
  columnvector_run <- which(run_november_sp$WardName == vars)
  run_selectedward <- run_november_sp[columnvector_run,]
  print(run_selectedward)
  # Create the plot!
  for (j in 1:nrow(run_november_sp)){
    run_map_plot <- tm_shape(run_selectedward) + 
      tm_lines(col = "blue", lwd=4, alpha=0.5)
  return(run_map_plot)
  }  
}
RunInWard(run_november_sp)
```








This R Markdown document is made interactive using Shiny. Unlike the more traditional workflow of creating static reports, you can now create documents that allow your readers to change the assumptions underlying your analysis and see the results immediately. 

To learn more, see [Interactive Documents](http://rmarkdown.rstudio.com/authoring_shiny.html).

## Inputs and Outputs

You can embed Shiny inputs and outputs in your document. Outputs are automatically updated whenever inputs change.  This demonstrates how a standard R plot can be made interactive by wrapping it in the Shiny `renderPlot` function. The `selectInput` and `sliderInput` functions create the input widgets used to drive the plot.

```{r eruptions, echo=FALSE}

```

## Embedded Application

It's also possible to embed an entire Shiny application within an R Markdown document using the `shinyAppDir` function. This example embeds a Shiny application located in another directory:

```{r tabsets, echo=FALSE}
shinyAppDir(
  system.file("examples/06_tabsets", package = "shiny"),
  options = list(
    width = "100%", height = 550
  )
)
```

Note the use of the `height` parameter to determine how much vertical space the embedded application should occupy.

You can also use the `shinyApp` function to define an application inline rather then in an external directory.

In all of R code chunks above the `echo = FALSE` attribute is used. This is to prevent the R code within the chunk from rendering in the document alongside the Shiny components.



